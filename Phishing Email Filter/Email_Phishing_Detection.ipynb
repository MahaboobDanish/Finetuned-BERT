{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943f012e",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "- `torch`: for processing tensor data and essential deep learning tools for AI training.\n",
    "- `transformers`: for various open-sorced state-of-art language and multimodal models.\n",
    "- `datasets`: for a wide range of structured datasets for NLP and vision tasks.\n",
    "- `accelerate`: for tools that optimize and simplify the AI trianing process.\n",
    "- `ibm_watson_ai`: for IBM Watson.ai APIs and services.\n",
    "- `matplotlib`: for additional plotting tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee493e",
   "metadata": {},
   "source": [
    "##### Installing Required Libraires (takes 10-15 min time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37bd37ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install torch==2.8.0\n",
    "%pip install transformers==4.55.4\n",
    "%pip install datasets==3.6.0\n",
    "%pip install accelerate==1.10.1\n",
    "# %pip install ibm_watsonx_ai==1.3.13\n",
    "%pip install gradio==5.45.0\n",
    "%pip install matplotlib==3.10.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2483062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show urllib3\n",
    "# !pip install urllib3==1.26.16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b493d96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U transformers requests\n",
    "# !pip install --upgrade transformers accelerate torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2e48aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6931a25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n",
      "/Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <08E12B12-6183-307E-BDA0-374FA8EBA2C9> /Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Expected in:     <709C1DF5-D253-3C66-87E2-C99FD3A259DF> /Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/danishkarur/opt/anaconda3/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "#### Importing All Required Libraries\n",
    "\n",
    "# Libraries for BERT Fine-tuning\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset, Dataset, DatasetDict, concatenate_datasets\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, pipeline\n",
    "\n",
    "# # Watsonx.ai client\n",
    "# from ibm_watsonx_ai import Credentials\n",
    "# from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "# from ibm_watsonx_ai.foundation_models.schema import TextChatParameters, TextChatResponseFormat, TextChatResponseFormatType\n",
    "\n",
    "# Gradio for simple shareable web app\n",
    "import gradio as gr\n",
    "\n",
    "# Basics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The following code is used to suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# The following library is fur managing directories/folders\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35388df",
   "metadata": {},
   "source": [
    "##### Define Helper Functions\n",
    "\n",
    "- Constructing Datasets\n",
    "- Modell Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fdb18c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_to_email_url(dataset):\n",
    "    \"\"\"\n",
    "    This function splits the original mixed dataset into\n",
    "    email and url datasets. The email has labels 0 and 1,\n",
    "    and the urls have labels 2 and 3.\n",
    "    \"\"\"\n",
    "    emails = []\n",
    "    urls = []\n",
    "    \n",
    "    for data_type in ['train','validation','test']:\n",
    "        email_content = dataset[data_type].filter(lambda smaple:smaple['label'] in [0,1])\n",
    "        url_content = dataset[data_type].filter(lambda sample:sample['label'] in [2,3])\n",
    "        \n",
    "        emails.append(email_content)\n",
    "        urls.append(url_content)\n",
    "    ds_email = concatenate_datasets(emails)\n",
    "    ds_url = concatenate_datasets(urls)\n",
    "    \n",
    "    return ds_email, ds_url\n",
    "\n",
    "\n",
    "def full_toy_data(dataset_full, n_train_legit, n_train_phish, n_test):\n",
    "    \"\"\"\n",
    "    This function constructs the toy dataset for this project.\n",
    "    \"\"\"\n",
    "    ds_train_leg = dataset_full['train'].filter(lambda example: example['label']==0).shuffle(seed=0).select(range(n_train_legit))\n",
    "    ds_train_phi = dataset_full['train'].filter(lambda example: example['label']==1).shuffle(seed=0).select(range(n_train_phish))\n",
    "    content_toy = []\n",
    "    label_toy = []\n",
    "    \n",
    "    for i in range(n_train_legit):\n",
    "        content_toy.append(ds_train_leg[i]['content'])\n",
    "        label_toy.append(ds_train_leg[i]['label'])\n",
    "        content_toy.append(ds_train_phi[i]['content'])\n",
    "        label_toy.append(ds_train_phi[i]['label'])\n",
    "        \n",
    "    ds_train = Dataset.from_dict({'content':content_toy, 'label':label_toy})\n",
    "    ds_test = dataset_full['test'].select(range(n_test))\n",
    "    ds = DatasetDict({'train':ds_train, 'test':ds_test})\n",
    "    return ds\n",
    "\n",
    "def evaluate(preds,labels):\n",
    "    \"\"\"\n",
    "    This function evaluates the performance of the model by comparing\n",
    "    its predictions to the ground-truth labels. Five things are evaluated:\n",
    "        1. Accuracy: percentage of correct predictions\n",
    "        2. Precision: percentage of correct positives among all predicted positives\n",
    "        3. Recall: percentage of correct positives among all ground-truth positives\n",
    "        4. F1-score: the harmonic mean of precision and recall\n",
    "        5. Confusion Matrix: visualize frequencies of true positives (TP), false positives (FP), true negatives (TN) and false negatives (FN)\n",
    "    \"\"\"\n",
    "    preds = np.array(preds)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    TP = np.sum((preds==1) & (labels==1)) # phishing correctly predicted \n",
    "    TN = np.sum((preds==0) & (labels==0)) # legitimate correctly predicted\n",
    "    FP = np.sum((preds==1) & (labels==0)) # False alarm\n",
    "    FN = np.sum((preds==0) & (labels==1)) # missed phishing\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
    "    precision = TP / (TP + FP) if (TP + FP)> 0 else 0.0\n",
    "    recall = TP / (TP + FN) if (TP + FN)>0 else 0.0\n",
    "    \n",
    "    f1 = (2 * precision * recall) / (precision + recall) if (precision + recall)>0 else 0.0\n",
    "    \n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")\n",
    "    \n",
    "    # Confusion matrix array\n",
    "    cm = np.array([[TN, FP],\n",
    "                   [FN, TP]])\n",
    "    \n",
    "    classes = [\"Legitimate\", \"Phishing\"]\n",
    "    \n",
    "    # Add text labels\n",
    "    labels = [[\"TP\", \"FP\"],\n",
    "              [\"FN\", \"TN\"]]\n",
    "    \n",
    "     # Plot confusion matrix manually\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    \n",
    "    # Show numbers inside cells\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, f\"{labels[i][j]}={cm[i, j]}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=12)\n",
    "\n",
    "    # Add labels\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    ax.set_xlabel(\"Predicted Label\")\n",
    "    ax.set_ylabel(\"True Label\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    # Add colorbar\n",
    "    plt.colorbar(im, ax=ax)\n",
    "    plt.show()\n",
    "\n",
    "    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8322114",
   "metadata": {},
   "source": [
    "### Preparing PhishingEmailDetectionv2.0 Dataset\n",
    "\n",
    "\n",
    "Dataset: [PhishingEmailDetectionv2.0](https://huggingface.co/datasets/cybersectony/PhishingEmailDetectionv2.0)\n",
    "\n",
    "Before training, it’s important to understand the data we are working with. Below are some descriptive statistics of the dataset:\n",
    "\n",
    "- __Number of samples__: 22,644 Emails and 177,356 URLs\n",
    "- __Classes__: Legitimate Email (0), Phishing Email (1), Legitimate URL (2), Phishing URL (3)\n",
    "- __Class distribution__: 5.7% (0), 5.6% (1), 44.3% (2), 44.5% (3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc61507f",
   "metadata": {},
   "source": [
    "##### Load Dataset\n",
    "Load dataset directlty from the huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0464b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ef2e1a9cd134d9b820a9e52a599eb02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ed271d0541f4d1782c586fafb6027c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/27.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a7eb6e0ca542dfa5a62a26e9aa2b78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/3.17M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f60e4764dc4b43930201f01be3f91c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/9.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d1a2e264934abea61c9bca5b0f2a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb7d8d9770b74feeb64338236cc0ce8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/20000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ce415f4e1741229fad686edb383bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['content', 'label'],\n",
      "        num_rows: 20000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['content', 'label'],\n",
      "        num_rows: 60000\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"cybersectony/PhishingEmailDetectionv2.0\")\n",
    "label_mapping = {0: 'legitimate email', 1: 'phishing email', 2: 'legitimate url', 3: 'phishing url'}\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8793694c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_labels {0, 1, 2, 3}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set(ds['train']['label'])\n",
    "print(\"unique_labels\",unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc5cf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Label index 0 -> Label value 'legitimate email'\",\n",
       " \"Label index 1 -> Label value 'phishing email'\",\n",
       " \"Label index 2 -> Label value 'legitimate url'\",\n",
       " \"Label index 3 -> Label value 'phishing url'\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f\"Label index {label} -> Label value '{label_mapping[label]}'\" for label in unique_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833b535e",
   "metadata": {},
   "source": [
    "To obtain the 100-th smaple from the trianing split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cfb9b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'https://www.schloebe.de', 'label': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = ds['train'][100]\n",
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bc7220",
   "metadata": {},
   "source": [
    "Here the label `2` i.e legitimate url and URL `https://www.schloebe.de`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3864e3",
   "metadata": {},
   "source": [
    "This dataset contains three portions: train, validation and test.\n",
    "    \n",
    "    Each smaple contains two daafields:\n",
    "    - First field: \"content\" for email/url body\n",
    "    - Second field: \"label\" for the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a07b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate the email and the url dataset\n",
    "ds_email, ds_url = split_data_to_email_url(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61884262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'empty', 'label': 1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_email.filter(lambda sample: sample['content']=='empty')[0] #select a missing value data row with filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac7504c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_email = ds_email.filter(lambda sample: sample['content']=='empty')[0] # select a missing value data row with filter function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2a7290",
   "metadata": {},
   "source": [
    "##### Remove the Empty rows by filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90624644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8c0958bd9f41b4a6d5068039bcd732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/22644 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715dc5ffd9ad4c7b8ba98640ec37e0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/177356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d343e6c3eb62404b97523202503dbed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/177356 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_email = ds_email.filter(lambda sample:sample['content']!='empty')\n",
    "ds_url = ds_url.filter(lambda sample: sample['content']!='empty')\n",
    "\n",
    "# for ds_url, we also need to map the tables to 0 and 1\n",
    "\n",
    "new_url_labels = {2:0,3:1}\n",
    "\n",
    "def remap_labels(example):\n",
    "    example['label'] = new_url_labels[example['label']]\n",
    "    return example\n",
    "\n",
    "ds_url = ds_url.map(remap_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70577f8",
   "metadata": {},
   "source": [
    "##### Check is there are duplicates inside the dataset ds_email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1f811d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4094</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4764</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4771</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6278</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10123</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13403</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14217</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14701</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15267</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17353</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18340</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19531</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21867</th>\n",
       "      <td>\\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  label\n",
       "4094   \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "4764   \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "4771   \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "6278   \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "7622   \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "10123  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "13403  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "14217  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "14301  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "14701  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "15267  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "17353  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "18340  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "19531  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1\n",
       "21867  \\nÃÂ \\nDear \\n              Homeowner,ÃÂ    ...      1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_email.to_pandas().loc[ds_email.to_pandas()['content']== ds_email.to_pandas().value_counts().index[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a347a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Unique emails\n",
    "unique_df = ds_email.to_pandas().drop_duplicates(subset=\"content\",keep = \"first\")\n",
    "\n",
    "# Convert back to Datasets\n",
    "ds_email = Dataset.from_pandas(unique_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c662af92",
   "metadata": {},
   "source": [
    "###### The url dataset is left for exercises. Let's print out two sample emails from the ds_email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c1a3d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12630961fbea43b59ee984592d4806fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234c9279779d4eb68c1d58602567ebd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/17536 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 17536 training data in total. 10979 legit emails and 6557 phishing emails.\n",
      "\n",
      "Here is one legitimate email sample: revised - transitional steering committee meeting here are the details for the transitional steering committee meetings : this meeting will take place every wednesday at 10 : 00 a . m . ( cst ) commencing on february 6 th . dial - in number : 877 - 232 - 4392 host code : 505813 ( louise ) participant code : 969747 tammie schoppe enron americas - office of the chair assistant to louise kitchen 713 . 853 . 4220 office 713 . 646 . 8562 fax 713 . 253 . 2131 mobile.\n",
      "\n",
      "Here is one phishing email sample: Dear ricardo1 ,\n",
      "COST EFFECTIVE Direct Email Advertising\n",
      "Promote Your Business For As Low As \n",
      "$50 Per \n",
      "1 Million\n",
      " Email Addresses\n",
      "MAXIMIZE YOUR MARKETING DOLLARS!\n",
      "Complete and fax this information form to 309-407-7378.\n",
      "A Consultant will contact you to discuss your marketing needs.\n",
      "NAME:___________________________________________________________________\n",
      "COMPANY:_______________________________________________________________\n",
      "ADDRESS:________________________________________________________________\n",
      "CITY:_____________________________________________________________________\n",
      "STATE:___________________________________________________________________\n",
      "PHONE:___________________________________________________________________\n",
      "E-MAIL:__________________________________________________________________\n",
      "WEBSITE: (Not Required)_______________________________________________________\n",
      "___________________________________________________________________________\n",
      "___________________________________________________________________________\n",
      "*COMMENTS: (Provide details, pricing, etc. on the products and services you wish to market)\n",
      "___________________________________________________________________________\n",
      "___________________________________________________________________________\n",
      "___________________________________________________________________________\n",
      "___________________________________________________________________________\n",
      " [247(^(PO1:KJ)_8J7BJK9^\":}H&*TG0BK5NKIYs5]\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "# Exploring the training data\n",
    "\n",
    "num_data = ds_email.num_rows\n",
    "legit_emails = ds_email.filter(lambda example:example['label']==0)\n",
    "phish_emails = ds_email.filter(lambda example:example['label']==1)\n",
    "\n",
    "example_legit_email = legit_emails[0]['content']\n",
    "example_phish_email = phish_emails[1]['content']\n",
    "\n",
    "print(f'There are {num_data} training data in total. {legit_emails.num_rows} legit emails and {phish_emails.num_rows} phishing emails.')\n",
    "print()\n",
    "print(f'Here is one legitimate email sample: {example_legit_email}.')\n",
    "print()\n",
    "print(f'Here is one phishing email sample: {example_phish_email}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9473856",
   "metadata": {},
   "source": [
    "###### Split the Dataset into Training and Testing\n",
    "We use the built-in function of the huggingface datasets to perform the splitting.\n",
    "\n",
    "One argument we need to set is the `test_size`, which determines the ratio of the test portion to the train portion. The popular choice for `test_size` is 0.2, i.e., 20% of the dataset will be randomly selected to form the test portion. There are other choices as well, for example 75 to 25 split and 70 to 30 split.\n",
    "\n",
    "In this notebook, we set `test_size=0.2`. We first randomly shuffle the dataset with a specific seed=0 for the purpose of reproducibility by `shuffle`, and then use `train_test_split` for perform the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8542e59d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['content', 'label', '__index_level_0__'],\n",
       "        num_rows: 14028\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['content', 'label', '__index_level_0__'],\n",
       "        num_rows: 3508\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_email = ds_email.shuffle(seed=0) # random\n",
    "ds_email = ds_email.train_test_split(test_size = 0.2, shuffle=False)\n",
    "\n",
    "ds_email"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c83d1fc",
   "metadata": {},
   "source": [
    "##### Construct a Toy Dataset for Training Demo\n",
    "\n",
    "Since the environment is not equipped with GPUs (Graphical Processing Units), to demonstrate how to fine-tune a BERT-based phishing email detector, we need to construct a much smaller dataset from the original ds_email. What we will do here is to randomly sample 3 legitimate emails and 3 phishing emails (to keep the two classes balanced), and randomly sample 1 email from the test dataset. These two sampling processes are wrapped inside the helper function `full_toy_data`.\n",
    "\n",
    "Again, this toy dataset is only for demonstration here in the online environment. If you have local GPUs, please ignore this toy dataset construction, and directly head to the training steps. If you are doing your code online, don't worry, we will provide you a pre-trained and saved model configurations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac1808e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bf9f54d2cf4cb99e1d7a91b8bd85b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebae669f09484de49e84b674dfe544f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/14028 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_toy = full_toy_data(dataset_full=ds_email,\n",
    "                       n_train_legit = 3,\n",
    "                       n_train_phish = 3,\n",
    "                       n_test = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "69553d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['content', 'label'],\n",
      "        num_rows: 6\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['content', 'label', '__index_level_0__'],\n",
      "        num_rows: 1\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(ds_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc85751",
   "metadata": {},
   "source": [
    "## Fine-TUning BERT for Phishing Email Classification\n",
    "\n",
    "The Hugging Face Transformers library provides a wide selection of accessible pre-trained models, including various versions of BERT, RoBERTa, and their lightweight distilled counterparts. For this project, we choose the model `distilbert-base-uncased` as our pre-trained backbone.\n",
    "\n",
    "- `__distilbert-base-uncased__` is a distilled version of BERT that retains most of BERT’s performance while being faster and more memory-efficient.\n",
    "- The model has been trained on a large corpus of English text and does not differentiate between uppercase and lowercase letters (“uncased”), which is particularly useful in phishing detection since attackers often vary capitalization to evade simple keyword filters.\n",
    "- The `“distillation”` process refers to knowledge distillation, a technique where a smaller model (the student) is trained to mimic the behavior of a larger, more complex model (the teacher).\n",
    "- In the case of `DistilBERT`, the student model learns from BERT by approximating its output distributions, capturing most of its representational power while reducing size and computational cost.\n",
    "-  As a result, DistilBERT is roughly __40% smaller__ and __60% faster__ than BERT, yet preserves about __97%__ of its performance on key NLP benchmarks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c40505a",
   "metadata": {},
   "source": [
    "### Load the Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "31ad96b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a pre-trained model\n",
    "model_name = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f224a9",
   "metadata": {},
   "source": [
    "#### Text Processing\n",
    "1. `tokenizer` using `AutoTokenizer`:\n",
    "    - Input: `model_name`\n",
    "    - Converts raw text into numerical tokens that model can understand.\n",
    "    - Splits text into smaller units such as subwords, characters, word pieces. e.g. 'processing' -> 'process' and 'ing'\n",
    "    - Each token is then mapped to an IntergerID from the model's vocabulary,  e.g. 'process' -> 201, 'ing' -> 520.\n",
    "    - For `uncased` language models, their tokenizers map the original sentence and its uncased version to the same output. For example, \"Where is Peter\" and \"where is peter\" will be tokenized by same tokens.\n",
    "    \n",
    "2. `model` using `AutoModelForSequenceClassification`\n",
    "    - Input: `model_name` and `num_labels` (number of classes, which is 2 in our case: phishing 0 and legitimate 1).\n",
    "    - Configures the pre-trained model specified by `model_name`.\n",
    "    - Initializes some new weights for downstream fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0256f00d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6856efa3e6b54063961d2cd7241c0086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "num_labels = 2\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb77a39",
   "metadata": {},
   "source": [
    "### Preporcess the Text Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6f856cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fw : sep ytd originations - - - - - original message - - - - - from : carter , carol sent : thursday , october 04 , 2001 4 : 57 pm to : killen , faith subject : sep ytd originations'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = ds_toy['train'][0]['content']\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c6c1a",
   "metadata": {},
   "source": [
    "- `input_ids` represents the actual tokenized values of the text\n",
    "- Notice that `0` tokens are added at the end - these are `padding tokens`.\n",
    "- `attention_mak` tells the model which token to pay attention\n",
    "    - A value `1` means the token is real input.\n",
    "    - A value of `0` menas the token should be ignored (padding)\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "122deb5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of input_ids: 512\n",
      "\n",
      "First 10 input_ids: [101, 1042, 2860, 1024, 19802, 1061, 2102, 2094, 4761, 10708]\n",
      "\n",
      "Last 10 input_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Unique tokens in input_ids: {1024, 0, 2434, 4752, 1042, 8594, 4761, 5401, 3102, 1061, 2860, 2094, 2741, 2102, 7610, 2368, 3395, 5708, 2255, 5840, 2000, 10708, 9432, 19802, 2013, 101, 102, 2541, 1010, 1011, 4471, 1018}\n",
      "\n",
      "First 10 attention_mask values: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "\n",
      "Last 10 attention_mask values: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Unique values in attention_mask: {0, 1}\n"
     ]
    }
   ],
   "source": [
    "# Run tokenizer with padding and truncation\n",
    "\n",
    "example_tokens = tokenizer(\n",
    "    example, \n",
    "    padding = \"max_length\",\n",
    "    truncation = True\n",
    ")\n",
    "# How the exampel token looks like\n",
    "# print(\"\\nExample Token: \",example_tokens)\n",
    "# Lenght of tokenized input\n",
    "print(\"\\nLength of input_ids:\", len(example_tokens[\"input_ids\"]))\n",
    "\n",
    "# First 10 input tokens\n",
    "print(\"\\nFirst 10 input_ids:\", example_tokens[\"input_ids\"][:10])\n",
    "\n",
    "# Last 10 input tokens (should include padding = 0)\n",
    "print(\"\\nLast 10 input_ids:\", example_tokens[\"input_ids\"][-10:])\n",
    "\n",
    "# Unique set of tokens in the input\n",
    "print(\"\\nUnique tokens in input_ids:\", set(example_tokens[\"input_ids\"]))\n",
    "\n",
    "# First 10 attention mask values\n",
    "print(\"\\nFirst 10 attention_mask values:\", example_tokens[\"attention_mask\"][:10])\n",
    "\n",
    "# Last 10 attention mask values (should contain 0 for padding)\n",
    "print(\"\\nLast 10 attention_mask values:\", example_tokens[\"attention_mask\"][-10:])\n",
    "\n",
    "# Unique values in the attention mask (should be {0, 1})\n",
    "print(\"\\nUnique values in attention_mask:\", set(example_tokens[\"attention_mask\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f777c2",
   "metadata": {},
   "source": [
    "To pass the tokenizer to each data of the dataset, we first define a tokenization function:\n",
    "- `tokenize_function` - applies the tokenizer to convert to convert each email's content into integer tokens. Key arguments include:\n",
    "    - `text`: the email body (our input)\n",
    "    - `padding=max_length`: pads sequences shorter than maximum lenght with [PAD] tokens.\n",
    "    - `truncation=True`: shortens sequences longer than the maximum length.\n",
    "    \n",
    "The `tokenize_function` is then mapped to the entire dataset using .map(), which processes all smaples in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c82dd9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adac3bbab2a4f73be81b6d008f9b39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483d73341d064bf4952de3c7396d46be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a tokenization function\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['content'], padding='max_length', truncation=True)\n",
    "\n",
    "# Apply the tokenizer to entire dataset\n",
    "tokenized_datasets = ds_toy.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991c308b",
   "metadata": {},
   "source": [
    "##### Adjustments\n",
    "\n",
    "- HuggingFace's `Trainer` API, whihc we will be using for fine-tuning.\n",
    "    1. `input_ids`: the integer sequence of the tokenized text.\n",
    "    2. `attention_mask`: the binary indicators that tell the model which tokens are real input(1) and which are just padding (0), so it can be ignore padding during attention calculations.\n",
    "    3. `labels`:class\n",
    "    \n",
    "To match with this dataset format, we use the follwoing codes to.\n",
    "1. Remove original \"content\" datafield.\n",
    "2. Rename the \"label\" datafield to `labels`.\n",
    "3. Set the data inside the dataset to `torch` datatype.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a96e798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the data for the model\n",
    "# Rename the 'labels' column to 'labels' for the Trainer API and remove unneeded columns\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"content\"])\n",
    "\n",
    "# Format the datasets to return PyTOrch tensors\n",
    "tokenized_datasets.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da551cf",
   "metadata": {},
   "source": [
    "#### Begin Fine-Tuning\n",
    "\n",
    "Set up Trainer API for our BERT model. We first create a `TrainingArguments` class object that contains all the trianing configurations.\n",
    "\n",
    "__Each Variables__\n",
    "- `output_dir`: Directory to save the model checkpoints and results.\n",
    "- `evaluation_strategy`: Defines how often evaluation is run during training (e.g., \"epoch\" or \"steps\").\n",
    "- `per_device_train_batch_size`: Number of training samples processed per device(GPU/CPU) in each forward/backward pass.\n",
    "- `per_device_eval_batch_size`: Number of evaluation samples processed per device when running validation.\n",
    "- `num_train_epochs`: NUmber of full passes over the training dataset.\n",
    "- `logging_dir`: Directory to store training logs for visualization (e.g., TensorBoard).\n",
    "- `report_to`: Specifies reporting integrations (e.g., \"tensorboard\", \"wandb\", or \"none\") dor monitoring training progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43a32773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",  # create a new folder \"results\" in the current directory\n",
    "    eval_strategy = \"epoch\",\n",
    "    per_device_train_batch_size = 16,\n",
    "    per_device_eval_batch_size = 16,\n",
    "    num_train_epochs = 1, # train for 1 epochs\n",
    "    logging_dir = \"./logs\", # create a new folder \"logs\" in the current directory\n",
    "    report_to = \"none\",  # we don't use reporting tools here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10731e7",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Since our task involves only two classes (__phishing__ vs. __legitimate__), the `Trainer` automatically applies __Binary Cross-Entropy Loss (BCELoss)__ as the optimization objective. Formally, for a single training example, the BCELoss is defined as:  \n",
    "\n",
    "$$\n",
    "\\mathcal{l}(y, \\hat{y}) = - \\big[ y \\cdot \\log(\\hat{y}) + (1 - y) \\cdot \\log(1 - \\hat{y}) \\big]\n",
    "$$\n",
    "\n",
    "where:  \n",
    "- $y \\in \\{0,1\\}$ is the true label (0 = legitimate, 1 = phishing)  \n",
    "- $\\hat{y} \\in [0,1]$ is the predicted probability that the input belongs to class 1 (phishing)  \n",
    "\n",
    "The overall loss is averaged across all training samples in a batch, that is: \n",
    "$$\n",
    "\\mathcal{L}(\\{y_i\\}_{i=1}^N, \\{\\hat{y}_i\\}_{i=1}^N) = \\frac{1}{N}\\sum_{i=1}^N \\mathcal{l}(y_i,\\hat{y}_i)\n",
    "$$\n",
    "\n",
    "where $N$ is the number of samples, $\\{y_i\\}_{i=1}^N$ and $\\{\\hat{y}_i\\}_{i=1}^N$ are the collections of ground-truth labels and predictions respectively. \n",
    "\n",
    "Intuitively, the loss $\\mathcal{L}$ is designed such that:  \n",
    "\n",
    "- If the true label is **1** (*phishing*), the model is penalized heavily when it assigns a low probability to phishing.  \n",
    "- If the true label is **0** (*legitimate*), the model is penalized when it assigns a high probability to phishing.  \n",
    "\n",
    "By minimizing BCELoss during training, the classifier learns to assign high probabilities to phishing emails and low probabilities to legitimate ones.\n",
    "\n",
    "Now we use the model, the `training_args`, and the training/evaluation datasets to create a `Trainer` object to carry out fine-tuning. \n",
    "\n",
    "At the end, we save the trained model to a specified directory \"saved_model\" by ``.save_pretrained()``.\n",
    "\n",
    "<p style=\"color:#c62828; font-size:1.1rem; font-weight:600; margin:0;\">\n",
    "  This may take over  10-15 minutes\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45a6976f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:14, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.658249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_datasets[\"train\"],\n",
    "    eval_dataset = tokenized_datasets[\"test\"]\n",
    ")\n",
    "\n",
    "# Start training, may take up to 5 minites to go through toy_dataset with 1 epoch\n",
    "trainer.train()\n",
    "\n",
    "# Save model to the saved_model_toy folder\n",
    "model.save_pretrained('./saved_model_toy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ca26b6",
   "metadata": {},
   "source": [
    "NOte: The toy model above was trained on only 6 samples, so its predictions are highly unreliable. To demostrate meaningful results, a fully fine-tuned model is found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ebe1cd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'saved_model' created.\n"
     ]
    }
   ],
   "source": [
    "# Create a folder to strore the full model info\n",
    "\n",
    "directory_name = \"saved_model\"\n",
    "\n",
    "if os.path.isdir(directory_name):\n",
    "    print(f\"The directory '{directory_name}' exists.\")\n",
    "else:\n",
    "    os.mkdir(directory_name)\n",
    "    print(f\"Directory '{directory_name}' created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1614234",
   "metadata": {},
   "source": [
    "##### Get the fine-tuned model files frmo the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83c853c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-03 14:04:51--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/dCGCWYjklYFBLtc-_dZqXw/config.json\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 563 [application/json]\n",
      "Saving to: 'saved_model/config.json'\n",
      "\n",
      "config.json         100%[===================>]     563  --.-KB/s    in 0s      \n",
      "\n",
      "2025-11-03 14:04:52 (179 MB/s) - 'saved_model/config.json' saved [563/563]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-03 14:04:52--  https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WA2Wr0aaIACXud0--T8Lew/model.safetensors\n",
      "Resolving cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)... 169.63.118.104\n",
      "Connecting to cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud (cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud)|169.63.118.104|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 267832560 (255M) [application/octet-stream]\n",
      "Saving to: 'saved_model/model.safetensors'\n",
      "\n",
      "model.safetensors   100%[===================>] 255.42M  5.76MB/s    in 42s     \n",
      "\n",
      "2025-11-03 14:05:35 (6.01 MB/s) - 'saved_model/model.safetensors' saved [267832560/267832560]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -P saved_model 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/dCGCWYjklYFBLtc-_dZqXw/config.json'\n",
    "!wget -P saved_model 'https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/WA2Wr0aaIACXud0--T8Lew/model.safetensors'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7b0ed203",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = directory_name #path to the saved_model folder\n",
    "num_labels = 2\n",
    "model_full = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b03b28",
   "metadata": {},
   "source": [
    "##### Pipeline Creation for Easy Inference\n",
    "\n",
    "- `task`: the type of the downstream task, \"text-classification\" for this project.\n",
    "- `model`: the model to be used.\n",
    "- `tokenizer`: the tokenizer to be used.\n",
    "- `device`: the computing device, defined by `torch.device()` which sets device as \"cpu\" by default but \"cuda\" when gpu is available.\n",
    "- `top_k`: a positive integer that controls how many of the top-probability labels the pipeline returns  for each input. If `top_k=1`, it will print out the most probable label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fb6f5235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# define the device\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#create a pipeline for text classification using your fine-tuned model\n",
    "phishing_detector = pipeline(task=\"text-classification\", model=model_full, tokenizer = tokenizer, device = device, top_k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d452b26",
   "metadata": {},
   "source": [
    "### Evalaution on the Test Dataset\n",
    "\n",
    "Classification Metrics\n",
    "- __Accuracy__: THe portion of correctly classified emails ot of all test samples.\n",
    "- __Precision__: THe portion of emails predicted as phishing that are actually phishing.\n",
    "- __Recall__: THe portion of actual phishing emails correctly identified by the model.\n",
    "- __F1-Score__: THe harmonic mean of precisions and recall, balancing the trade-off between catching phishing emails and avoainding false alarms.\n",
    "\n",
    "Confusion Matrix:\n",
    "- __True Positive(TP)__: Phishing emails correctly identified as phishing.\n",
    "- __True Negative__(TN): Legitimate emails correctly identifiend as legitimate.\n",
    "- __Fasle Positive__(FP): Legitimate emails incorrectly flagged as phishing (false alarms)\n",
    "- __False Negative__(FN): Phishing emails incorrectly classified as legitimate (missed attacks).\n",
    "\n",
    "__Note__: A Strong phishing detection model should maximize TP and TN, while minimize FP and FN. In practice __high recall__ is particularly important, since missing a phishing email (FN) is more dangerous than ocassionally flagging a legitimate one (FP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f499f08",
   "metadata": {},
   "source": [
    "Note: Considering computaitonal constraints, here evaluationg only first 50 test emails in the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab8324e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0000\n",
      "Precision: 1.0000\n",
      "Recall   : 1.0000\n",
      "F1-score : 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 50\n",
    "ground_truth = ds_email['test']['label'][:N]\n",
    "email_test = ds_email['test']['content'][:N]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "preds = phishing_detector(email_test,truncation=True) #truncation=True for long sequences\n",
    "\n",
    "for i in range(len(preds)):\n",
    "    predictions.append(int(preds[i][0]['label'][-1:]))\n",
    "\n",
    "metrics = evaluate(predictions,ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a796dd",
   "metadata": {},
   "source": [
    "# LLM Applicaiton with IBM Watson\n",
    "\n",
    "__IBM Granite__ designed to deliver stronger reasoning, longer context handling, and improved performance across business tasks\n",
    "\n",
    "Key Variables:\n",
    "- `CREDENTIALS`: Authentication credentials that specify the IBM Cloud endpoint (API keys are optional in this environment).\n",
    "- `LLM_Granite`: The specific Granite model to load — here we use the 8B Instruct variant, optimized for instruction-following tasks.\n",
    "- `PROJECT_ID`: The IBM Cloud project where the inference job will run.\n",
    "- `SYSTEM_PROMPT`: A role-defining instruction that establishes the assistant as a security analyst tasked with analyzing emails and extracting suspicious words or phrases that may indicate phishing attempts.\n",
    "- `ModelInference` class is used to initialize the Granite model with the given project and credentials, making it ready to process inputs and return structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7212f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watsonx.ai client\n",
    "from ibm_watsonx_ai import Credentials\n",
    "from ibm_watsonx_ai.foundation_models import ModelInference\n",
    "from ibm_watsonx_ai.foundation_models.schema import TextChatParameters, TextChatResponseFormat, TextChatResponseFormatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55d0392",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS = Credentials(\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    # api_key = \"\"\n",
    ")\n",
    "LLM_Granite = \"ibm/granite-3-3-8b-instruct\"\n",
    "PROJECT_ID = \"skills-network\"\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a security assistant. You will be given an email, and please analyze the email and list all suspicious words or phrases that indicate a possible phishing attempt\n",
    "with explanations. \n",
    "At last, give your final judgement by ONLY answering Yes or No, and give your confidence score between 0 to 100.\n",
    "Please provide your analysis in the following JSON format: { \"explanations\": \"...\", \"final_judgement\": \"Yes/No\", \"confidence_score\": 0-100 }.\n",
    "\"\"\"\n",
    "\n",
    "llm = ModelInference(\n",
    "                model_id=LLM_Granite,\n",
    "                credentials=CREDENTIALS,\n",
    "                project_id=PROJECT_ID\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d153e7f",
   "metadata": {},
   "source": [
    "##### Define a function to run the LLM with a given email email_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85745dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_suspicious_contents(email_text):\n",
    "    response = llm.chat(\n",
    "                    messages=[\n",
    "                        {\n",
    "                            \"role\": \"system\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \"text\": SYSTEM_PROMPT}\n",
    "                            ]\n",
    "                        },\n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": [\n",
    "                                {\"type\": \"text\", \"text\": email_text}\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78176f1b",
   "metadata": {},
   "source": [
    "##### Example Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17728d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example\n",
    "email_text = \"\"\"Dear Customer,\n",
    "\n",
    "We noticed unusual activity in your PayPal account. For your protection, your account has been temporarily limited.  \n",
    "\n",
    "Please verify your account information immediately to avoid suspension.  \n",
    "\n",
    "Click the secure link below to restore access:  \n",
    "http://paypa1-security[.]com/verify  \n",
    "\n",
    "Failure to update your details within 24 hours will result in permanent account closure.  \n",
    "\n",
    "Thank you for your prompt attention,  \n",
    "PayPal Security Team\"\"\"\n",
    "\n",
    "phishing_explain = analyze_suspicious_contents(email_text)\n",
    "print(phishing_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0269e44a",
   "metadata": {},
   "source": [
    "###### Output:\n",
    "\n",
    "{\n",
    "  \"explanations\": \"The email claims to be from PayPal Security Team and mentions unusual activity in the recipient's PayPal account, urging immediate action to avoid account suspension. However, there are several suspicious elements: 1) The use of 'Dear Customer' instead of the recipient's name, indicating a generic mass email. 2) The email references clicking a secure link to verify account information, which is a common phishing tactic. 3) The link provided does not belong to PayPal’s official domain but instead uses 'paypa1-security[.]com', which is slightly altered. 4) The threat of permanent account closure if action is not taken within 24 hours creates a sense of urgency, prompting the recipient to act without closely scrutinizing the email's legitimacy.\",\n",
    "  \"final_judgement\": \"Yes\",\n",
    "  \"confidence_score\": 95\n",
    "}\n",
    "\n",
    "Confident score of 95 because several red flags are present, including non-personalization, vague accusation of unusual activity, blatant domain manipulation in the URL, and creation of urgency without providing any specific details through legitimate customer service channels. These elements collectively indicate a high likelihood that this is a phishing attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e01950f",
   "metadata": {},
   "source": [
    "##### Judgement\n",
    "\n",
    "Create a dictionary based on the response with `ast.literal_eval()` so that we can extract the answers and scores easily.\n",
    "\n",
    "`__ast.literal_eval()__` in Python is a function within the `ast` (Abstract Syntax Trees) module that safely evaluates a string containing a Python literal or container display. It is designed to parse and evaluate strings that represent basic Python data structures like numbers, lists and dictionaries etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cc605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "response_dict = ast.literal_eval(phishing_explain)\n",
    "print(response_dict)\n",
    "print(response_dict['explanations'])\n",
    "print()\n",
    "print(f'Final Judgement: {response_dict['final_judgement']}')\n",
    "print()\n",
    "print(f'Confidence: {response_dict['confidence_score']}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdb3b2b",
   "metadata": {},
   "source": [
    "## A sharable WebApp with Gradio\n",
    "\n",
    "`Gradio` is an open-source Python library that makes it easy to build and share interactive web applications for machine learning models with just a few lines of code. It provides user-friendly interfaces such as text boxes, sliders, or file uploaders, allowing anyone to test models in real time directly from a browser.\n",
    "\n",
    "First, let's define some functions that can organize the BERT predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0348f3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def organize_predictions(legit, message_show=False):\n",
    "    label_map = {'LABEL_0':'LEGITIMATE ✅', 'LABEL_1':'SUSPICIOUS ‼️'}\n",
    "    messages = []\n",
    "    confidence_scores = []\n",
    "    for b in range(len(legit)):\n",
    "        conf_score = -1\n",
    "        content_type = None\n",
    "        for item in legit[b]:\n",
    "            if item['score'] > conf_score:\n",
    "                conf_score = item['score']\n",
    "                content_type = label_map[item['label']]\n",
    "            if message_show:\n",
    "                print(f\"{label_map[item['label']]}, score: {round(item['score'],2)}\")\n",
    "        if message_show: \n",
    "            print(f'This content seems to be {content_type}.')\n",
    "        messages.append(f'This content seems to be {content_type}.')\n",
    "        confidence_scores.append(conf_score)\n",
    "    return messages, confidence_scores\n",
    "        \n",
    "\n",
    "def phishing_prediction(pipeline, email, message_show=False):\n",
    "    #We only process one email at a time\n",
    "    prediction_legit = pipeline(email)\n",
    "    messages, confidence_scores = organize_predictions(prediction_legit, message_show=message_show)\n",
    "    return prediction_legit, messages[0], confidence_scores[0]\n",
    "\n",
    "# Redefine our phishing_detector with top_k=None to have the confidence score.\n",
    "phishing_detector = pipeline(\"text-classification\", model=model_full, tokenizer=tokenizer, device=device, top_k=None)\n",
    "\n",
    "# Assemble BERT and LLM into one function\n",
    "def analyze_email(email):\n",
    "    prediction_legit, message, conf_score_BERT = phishing_prediction(phishing_detector, email)\n",
    "    phishing_explain = analyze_suspicious_contents(email)\n",
    "    print(\"DEBUG:\", phishing_explain)\n",
    "    try:\n",
    "        response_dict = json.loads(phishing_explain)\n",
    "    except Exception:\n",
    "        print(\"Response was not JSON:\\n\", phishing_explain)\n",
    "        response_dict = {\"final_judgement\": \"Unknown\", \"confidence_score\": \"0\", \"explanations\": \"Error while processing\"}\n",
    "#     response_dict = eval(phishing_explain)\n",
    "    conf_score_Granite = int(response_dict['confidence_score'])/100\n",
    "    conf_score = None #final confidence score\n",
    "\n",
    "    if conf_score_BERT < conf_score_Granite:\n",
    "        conf_score = conf_score_Granite\n",
    "        content_type = 'LEGITIMATE ✅' if response_dict['final_judgement'] == 'No' else 'SUSPICIOUS ‼️'\n",
    "        message = f'This content seems to be {content_type}.'\n",
    "    else:\n",
    "        conf_score = conf_score_BERT\n",
    "    \n",
    "    if 0.5 <= conf_score < 0.6:\n",
    "        decorate = \"😐 (low confidence)\"\n",
    "    elif 0.6 <= conf_score < 0.9:\n",
    "        decorate = \"🙂 (medium confidence)\"\n",
    "    else:\n",
    "        decorate = \"💪 (high confidence)\"\n",
    "    conf_score_message = f'{round(conf_score,2)*100}% {decorate}'\n",
    "    \n",
    "    return message, conf_score_message, response_dict['explanations']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c902a0e",
   "metadata": {},
   "source": [
    "##### Ready to build out web app. Here are some key components:\n",
    "\n",
    "- `with gr.Blocks() as demo`: Creates a Gradio app container (`demo`) using the `Blocks` API, which allows you to organize components in rows, columns, and sections.\n",
    "- `gr.Markdown(...)`: Adds formatted text to the interface. Here, it displays a title (`\"Phishing Email Detection Demo\"`) and instructions for the user.  \n",
    "- `email_body = gr.Textbox(...)`:  A multiline textbox where the user pastes the email body to be analyzed.  \n",
    "- `submit = gr.Button(\"Analyze Email\")`: A button labeled `\"Analyze Email\"`. When clicked, it triggers the email analysis function.  \n",
    "- `with gr.Row()`:  Creates a horizontal row layout to place multiple components side by side.  \n",
    "- `message = gr.Label(label=\"Message\")`: An output label that will display the prediction result (e.g., `\"Phishing detected\"` or `\"Legitimate email\"`).  \n",
    "- `confidence_out = gr.Label(label=\"Confidence Score\")`: An output label that shows the model’s confidence percentage along with an emoji indicator.  \n",
    "- `explanation_out = gr.Textbox(...)`: A read-only textbox where the suspicious words/phrases are displayed as an explanation. \n",
    "- `submit.click(...)`: Links the button to the analysis function.\n",
    "- `demo.launch(share=True)`: Starts the Gradio app and generates a public shareable link so others can access the phishing detection demo in their browser.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bbd5e40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## 🛡️ Phishing Email Detection Demo\")\n",
    "    gr.Markdown(\"Paste an email below to check if it's suspicious or legitimate.\")\n",
    "\n",
    "    # with gr.Row():\n",
    "    #     subject = gr.Textbox(label=\"Email Subject\", placeholder=\"Enter subject\")\n",
    "    email_body = gr.Textbox(label=\"Email Body\", lines=10, placeholder=\"Paste email content here...\")\n",
    "    submit = gr.Button(\"Analyze Email\")\n",
    "\n",
    "    with gr.Row():\n",
    "        message = gr.Label(label=\"Message\")\n",
    "        confidence_out = gr.Label(label=\"Confidence Score\")\n",
    "    explanation_out = gr.Textbox(label=\"Explanation\", lines=10, interactive=False)\n",
    "\n",
    "    submit.click(analyze_email, inputs=[email_body], outputs=[message, confidence_out, explanation_out])\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2981d6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40eca996",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrates how modern AI can be applied to phishing email detection effectively. We achieved the following:\n",
    "\n",
    "- **Fine-tuned Transformer Classifier**:  \n",
    "  We fine-tuned a lightweight transformer model (e.g., DistilBERT/DistilRoBERTa) on a phishing dataset to classify emails as *legitimate* or *suspicious*.  \n",
    "\n",
    "- **LLM as a Second Defense Layer**:  \n",
    "  We integrated a large language model (IBM Granite) to analyze emails further and extract suspicious keywords or phrases that may indicate phishing strategies.  \n",
    "\n",
    "- **User-Friendly Interface**:  \n",
    "  We built a Gradio web application that allows users to paste an email, receive a classification result, see the confidence score with visual cues (emojis), and read an explanation of why the email may be risky.  \n",
    "\n",
    "- **Improved Accuracy and Interpretability**:  \n",
    "  By combining a fine-tuned classifier with an LLM, the system not only improves detection performance but also increases transparency, helping users trust the results.  \n",
    "\n",
    "- **Real-World Relevance**:  \n",
    "  The project highlights how explainable AI tools can enhance cybersecurity by offering both automated detection and human-readable insights.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b007f7c",
   "metadata": {},
   "source": [
    "## URL Exercise\n",
    "\n",
    "###### 1. Preprocess the URL dataset for BERT fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afee56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ds_url created before.\n",
    "# Step 1: shuffle ds_url with seed 0.\n",
    "ds_url =\n",
    "\n",
    "# Step 2: split ds_url into train and test portions\n",
    "ds_url =\n",
    "\n",
    "# Step 3: tokenize it with .map and tokenize_function\n",
    "tokenizer_datasets = \n",
    "\n",
    "# Step 4: rename the 'labels' column to 'labels' for the Trainer API and remove unneeded columns\n",
    "tokenized_datasets = #rename labels\n",
    "tokenized_datasets = #remove contents\n",
    "\n",
    "# Step 5: format the datasets to return PyTorch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807b6aa2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "\n",
    "```python\n",
    "ds_url = ds_url.shuffle(seed=0)\n",
    "\n",
    "ds_url = ds_url.train_test_split(test_size=0.2, shuffle=False)\n",
    "\n",
    "tokenized_datasets = ds_url.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"content\"])\n",
    "\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc23ef6",
   "metadata": {},
   "source": [
    "##### 2. Exercise 2 - Set up BERT Trainer with respect to the URL dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c143a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: create a toy dataset for ds_url with 5 legit urls and 5 phishing urls, and 1 test data\n",
    "\n",
    "# Step 1: create a training argument class with batch size 1 and number of training epochs 2\n",
    "\n",
    "# Step 2: create a trainer object for the preprocessed URL dataset\n",
    "\n",
    "# Step 3: start training\n",
    "\n",
    "# Step 4: save model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cc8b4c",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Click here for Solution</summary>\n",
    "    \n",
    "```python\n",
    "ds_toy = full_toy_data(dataset_full=ds_url,\n",
    "                       n_train_legit=5,\n",
    "                       n_train_phish=5,\n",
    "                       n_test=1)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",          \n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    num_train_epochs=2,              \n",
    "    logging_dir=\"./logs\",            \n",
    "    report_to=\"none\",                \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"test\"],\n",
    ")\n",
    "\n",
    "# The following model.train() part is suppressed, because\n",
    "# it would take a lot of time to run on CPU. But for completeness,\n",
    "# we still include it here, and you may use it for local run.\n",
    "\n",
    "## Start training\n",
    "#trainer.train()\n",
    "\n",
    "## Save the model to the saved_model_toy_url folder\n",
    "#model.save_pretrained('./saved_model_toy_url/')\n",
    "```\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c009504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
